% kapitel2.tex
\chapter{Background}
\label{chapter:kap2}
\section{Notation}
Let us first define our notation. 
Random Variables will be noted as $X$ and random vectors $\vect{X} = \{X_1, X_2, \ldots, X_n\}$ will be denoted in bold.
The state space of a random variable will be denoted as a cursive letter of that random variable $\mathcal{X}$ and for a random vector likewise as $\vect{\mathcal{X}}$.
Parameters of a probability density function in the context of the canocical exponential family will usually be noted as $\vect{\theta}$.
Model parameters on the ith local device will be noted as $\vect{\theta^i}$, while $\vect{\theta_i}$ is the value at position i of the parameter vecttor.
For a multivariate gaussian normal $\vect{\theta} = \{\vect{\mu}, \vect{\Sigma}\}$ the model parameters usually consist of mean $\vect{\mu}$ and covariance matrix $\vect{\Sigma}$.
If necessary additional notations for model parameters will be introduced if necessary.
This may be the case when talking about the distribution of $\vect{\theta}$ to distinguish between the model parameters and the distribution of model parameters.

When talking about optimality of $\vect{\theta}$ \wrt the canocical exponential family we assume $\vect{\theta}^*$ to be the true, unknown parameter vector.
Then, $\vect{\hat{\theta}}$ is the oracle, that has seen all data and is the reference point for comparing local models and aggregates.
Furthermore, $\vect{\tilde{\theta}}$ denotes a local parameter vector and $\vect{\tilde{\theta}}^i$ the ith local parameter vector respectively.
\section{Probability Theory}
\section{Exponential Families}
\subsection{Asymptotic Normality}
\section{Probabilistic Graphical Models}
When estimating parameters of a distribution we may consider each feature a random variable and the data generated a result of a stochastic process based on this random variables.
Probabilistic Graphical Models (PGM) are a powerful tool to model conditional independencies between random variables. 
We express each random variable as a node in a graph and each edge between two nodes represents a dependency. 
With the exception of trees and graphs with bounded treewidth performing exact inference in such a Graph is NP-Hard.
This is a result from having to compute the marginal distribution, i.e., summing over all possible states of all maximum cliques inside the graph.
However, methods exist, such as loopy belief propagation to perform approximate inference.
We may also apply a junction tree algorithm to transform the graph into a tree, where exact inference is possible in polynomial time.

When considering probabilistic graphical models we usually utilize parametric distributions, that are part of the exponential family. 
Our goal is to estimate the parameters of such a distribution, which optimizes some criterion e.g. Maximum Likelihood or Maximum Entropy.


After estimating the parameters for each distribution and device, we employ an aggregation mechanic to create a composite model.
Distributed integer probabilistic graphical models \cite{piatkowski2019distributed} have recently been considered by Piatkowski.
In this specific scenario the models were aggregated using the average over all local models.
Other existing aggregation mechanics are discussed in section.
Additionally we need to define a stopping criterion where every device will stop sending messages to other devices, which means we require some kind of convergence.
This is usually the case when most devices have a similar local model.
In the following we will consider existing work on that specific research area and then lay out the necessary steps and challenges for the thesis.

\section{Distributed Learning}
There are mainly two different architectural approaches to distributed learning. 
The first approach is a decentralized approach without coordinator.
Communication between nodes is allowed and necessary to transmit some amount of data to reach an overall conclusion to the learning task.
The other approach involves a centralised coordinator node that broadcasts intermediate results or correction terms to local nodes.
The nodes in this approach send their data to the coordinator. 
Hybrid-Methods, where both types of architerure are mixed are also possible.
This work will focus on the second type, while also giving some theoretical insights to the decentralized approach.

\subsection{Sample Complexity}
One of the key questions of distributed learning is the number of samples required to obtain local models that are sufficiently good, i.e., when to stop learning and either start communication with the coordinator
or to terminate the algorithm and produce a final aggregate model. 
One such upper bound can be found by applying the Hoefding-Inequality to the expectation of the difference between the sufficient statistics of a probabislitc graphical model.
Given two average sufficient statistics we can employ the Hoefding Bound to guarantee the distance between these two to be smaller than some $\epsilon$ with probability $\delta$

\subsection{Model Aggregation}

\subsubsection{Averaging}
The most intuitive approach to model aggregation is done by simply computing the unbiased average of all model parameters.
\begin{equation}
    \frac{1}{n} \sum_{i=1}^n \theta^i
\end{equation}
\subsubsection{Weighted Averaging}
The first step towards a more refined approach to model aggregation is to turn the uninformative prior, that is, the equally weighted aggreagtes into an informed prior by some means.
\begin{equation}
     \sum_{i=1}^n \lambda_i \theta^i
\end{equation}

While this sounds quite easy in theory, the research on informative priors and prior-based learning is still prevalent and actively pursued.
One method involves weighting the local model parameters by its likelihood given probability distribution over these parameters.
Since the Maximum Likelihood Estimator for canonical exponential families is asymptotically normal we may use the likelihood of a gaussian normal as weights:
\begin{equation}
    \lambda_i = \frac{\log p(\theta \lvert \psi)}{\sum_{x\in \mathcal{X}} \log p(\theta \lvert \psi)}
\end{equation}
where the denominator is the normalizer for the probability distribution used, either discrete or continuous.
In case of a normal distribution we then have
\begin{equation}
    p(\theta \lvert \psi) = \mathcal{N}(\theta \lvert \vect{\mu}, \vect{\Sigma})
\end{equation}

\begin{equation}
    \lambda_i = \log \frac{1}{\sqrt{2\pi\lvert \vect{\Sigma} \rvert}} \cdot \exp^{-\frac{1}{2} \cdot (\vect{\theta} - \vect{\mu})^T\vect{\Sigma}^{-1}(\vect{\theta} - \vect{\mu}}
\end{equation}
\subsubsection{Radon Machines}
A more robust method to solve the issue of model aggregation is the computation of the geometric median.
While the geometric median is well defined, there exists no algorithm to exactly compute the geometric median in $\mathbb{R}^n$ dimensions.
However [CITE] introduced Radon Machines as method for model ensembling.
Computing the radon point of a set of points is a variant of the geometric median and closely related to the tukey depth. 
The solution to the equation is obtained by solving a system of linear equations.
However, this requires the computation of the radon point, which in euclidean space has $\mathbb{R}^n + 2$ dimensions.
This requires us to have at least $\mathbb{R}^n + 2$ models readily available and with further aggregation $\mathbb{R}^{r^n}$ as each hierachichal step increases the number of models required exponentially.

\subsubsection{Bootstrap Aggregagation}
With generative modelling we can easily sample additional data from local models by transferring the local model parameters to the coordinator node.
Sampling can be realized in various different ways such as Gibbs Sampling or Perturb and Map.
We then create a new Dataset from our samples and use this to train a new global model. 
This has been shown to work in CITE and for canonical expoential families this approach is analogous to computing the expected average sufficient statistics:
TODO PROOF:


\subsubsection{Performance-Weighted-Averaging}
Instead of using a federated approach we can also rely on a federated-decentralized hybrid approach. 
That is, we generate weights vor a weighted average based on some measure of local performance.
While this this does not gurantee good results for local performance of a single model, we can attempt to measure performance of local models on other local devices.
This approach essentially incorporates the idea of decentralized thresholding as featured in CITE RAN WOLFF.
Local Nodes communicate with each other and in this specific case we excchange parameter vectors to perform some kind of performance measure on the local data of each device.
This method still gurantees minimal computation cost, while also guranteeing the local data to remain private.
We then formulate some performance measure such as average accuracy on all other local data and use this to compute the weighted average on the coordinator.

