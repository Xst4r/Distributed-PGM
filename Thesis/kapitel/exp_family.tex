% kapitel2.tex
\chapter{Background}
\label{chapter:kap2}

\section{Notation}
\label{sec:nota}
Let us first define our notation. 
Random Variables will be noted as $X$ and vectors will be written in bold letters, e.g. a vector of random variables $\vect{X} = \{X_1, X_2, \ldots, X_m\} \in \mathbb{R}^m$.
The state space of a random variable will be denoted as a cursive letter of that random variable $\mathcal{X}$ and the statespace for  a random vector likewise as $\vect{\mathcal{X}}$.
Parameters of a probability density function in the context of the canocical exponential family will usually be noted as $\vect{\theta} \in \mathbb{R}^n, \quad \mathbb{N}^+$.
Here $\mathbb{N}^+$ is defined as $ \mathbb{N}^+ = \mathbb{N} \setminus \{0\}$.
Model parameters on the i$^{th}$ local device will be noted as $\vect{\theta^i}$, while $\vect{\theta_i}$ is the entry at the i$^{th}$ position of the parameter vector.
A multivariate gaussian normal distribution for example has parameters of the form $\vect{\theta} = (\vect{\mu}, \vect{\Sigma})$, with mean $\vect{\mu} \in \mathbb{R}^{n}$ and covariance matrix $\vect{\Sigma} \in \mathbb{R}^{n \times n}$.
Additional notations for model parameters will be introduced if necesesary.
\todo{More generally any variable denothed with \* is optimal, \^ is global and \~ is local}
In the context of optimization and optimality we assume $\vect{\theta}^*$ to be the true, unknown parameter vector.
The global parameters vectors, i.e., the parameters obtained by a global model, which has access to all available data is denoted as  $\vect{\hat{\theta}}$.
Finally, $\vect{\tilde{\theta}}$ denotes any local parameter vector and $\vect{\tilde{\theta}}^{(i)}$ the i$^{th}$ local parameter vector respectively.


\section{Probability Theory}
This is the Bayes Theorem:
\begin{equation}
    P (A \lvert B) = \frac{P(B \lvert A) \cdot P(A)}{P(B)}
\end{equation}


\section{Exponential Families}
\label{sec:expf}

We will now introduce a convenient property of parameters from canonical exponential families, asymptotic normality of the maximum likelihood estimator. 

\subsection{Asymptotic Normality}
\label{ssec:asymp}
The Maximum Likelihood Estimator of canonical exponential families is consistent, regular and thus asymptotic normal i.e. $\sqrt{n}(\theta - \theta^*) \sim \mathcal{N}(0, i(\theta^*)^{-1})$.
Implying, that the paremeters follow a normal distribution with the  true parameter vector as mean an the inverse fisher information as covariance, with 

\begin{equation}
    i(\theta^*) = \frac{\partial}{\partial^2 \vect{\theta}} p(x \lvert \vect{\theta})
\end{equation}

being the fisher information matrix.

We can interpret this result in such way that a set of parameter vectors obtained from data sets $\{\mathcal{D}_1, \ldots \mathcal{D}_n\}$ is normally distributed around the true parameter vector for a sample size of $n \leftarrow \infty$. 
This in turn implies that we can treat parameter vectors of local devices as samples from such a distribution and use this to estimate the maximum likelihood of the parameter space.
Addtionally we can use some $\vect{\theta}$ and assume this to be $\theta^*$ and use the result for sampling additional models.


\section{Probabilistic Graphical Models}
\label{sec:pgm}
When dealing with statistical (bayesian) models our goal usually is to estimate a set of parameters of a predetermined distribution that reduces the risk of predicting the wrong outcome (Risk Minimization). 
This is usually done by maximizing the Likelihood of the parameters having generated the data set $\mathcal{D}$ (see \ref{ssec:train}).

Let $\vect{X}$ be a random vector as defined in secition \ref{sec:nota}. 
Each entry in $X_i \in \vect{X}$ corresponds to a single random variable.
The most simple statistical models model each random variable individually while not accounting for dependencies between two or more variables.
This leads to worse estimates as the model can not capture the full scope of the underlying distribution.
With Probabilistic Graphical Models we can capture the underlying dependencies between these random variables in order to create a better estimate for the assumed distribution $\mathcal{D}$ adheres to.

When estimating parameters of a distribution we may consider each feature a random variable and the data generated a result of a stochastic process based on this random variables.
Probabilistic Graphical Models (PGM) are a powerful tool to model conditional independencies between random variables. 
We express each random variable as a node in a graph and each edge between two nodes represents a dependency. 
With the exception of trees and graphs with bounded treewidth performing exact inference in such a Graph is NP-Hard.
This is a result from having to compute the marginal distribution, i.e., summing over all possible states of all maximum cliques inside the graph.
However, methods exist, such as loopy belief propagation to perform approximate inference.
We may also apply a junction tree algorithm to transform the graph into a tree, where exact inference is possible in polynomial time.

When considering probabilistic graphical models we usually utilize parametric distributions, that are part of the exponential family. 
Our goal is to estimate the parameters of such a distribution, which optimizes some criterion e.g. Maximum Likelihood or Maximum Entropy.


After estimating the parameters for each distribution and device, we employ an aggregation mechanic to create a composite model.
Distributed integer probabilistic graphical models \cite{piatkowski2019distributed} have recently been considered by Piatkowski.
In this specific scenario the models were aggregated using the average over all local models.
Other existing aggregation mechanics are discussed in section.
Additionally we need to define a stopping criterion where every device will stop sending messages to other devices, which means we require some kind of convergence.
This is usually the case when most devices have a similar local model.
In the following we will consider existing work on that specific research area and then lay out the necessary steps and challenges for the thesis.

\subsection{Structure}
\label{ssec:struc}
We model the independency structure of $\vect{X}$ as a graph, where each vertex corresponds to a random variable and each edge is a dependency between two variables.
Formally, let $G = (\vect{X},E)$ be a Graph with $\vect{X} =\{X_1 \ldots, X_n\}$, $\vect{\mathcal{X}} = \{\mathcal{X}_1, \ldots, \mathcal{X}_n\}$ and $E \subseteq \vect{X} \times \vect{X}$
\paragraph{Markov Property}

\subsubsection{Structure Learning}
    Determining the Structure for the graph is important as we want to model the actual dependencie
    between random variables. 
    We may decide to drop dependencies in order to simplify the model, which allows for faster and exact training(in case the graph is a tree).
    
    We will use the Chow-Liu algorithm to approximate a independency structure, which always results in a tree.
    The algorithm computes the cross entropy for every pair of nodes and then computing the minimum spanning tree to 
    obtain the edges with the largest correlation.
    This limits the clique size in the graph to two, resulting in a tree, but also limiting the number of nodes that depend on each other.

    In this work the Chow-Liu algorithm is used for all independency structure approximations.
\subsection{Training}
\label{ssec:train}

Exponential Family is family of parametrized densities
Parameters have to be estimated
Maximum Likelihood Estimation
Given Data maximize Likelihood of Data being generated by distribution
Maximization over Distribution Parameters 
Negative Average Log Likelihood to prevent numerical errors
In general no closed form solution
Derivative is average sufficient statistics + expectation of $\vect{X}$
Log Partition is P-Complete, however solvable in poly time for trees.

optimization via Belief Propagation -> Inference
\subsection{Inference}
\label{ssec:inf}

Computing Clique Marginals
Belief Propagation
Exact for Trees 
Loopy Belief Propagation for non-tree Graphs

Since we are using the Chow-Lio algorithm to approximate the independency structure it is sufficient to use Belief Propagation for inference as this is guaranteed to be optimal and deterministic on trees.

\section{Distributed Learning}
There are mainly two different architectural approaches to distributed learning. 
The first approach is a decentralized approach without coordinator.
Communication between nodes is allowed and necessary to transmit some amount of data to reach an overall conclusion to the learning task.
The other approach involves a centralised coordinator node that broadcasts intermediate results or correction terms to local nodes.
The nodes in this approach send their data to the coordinator. 
Hybrid-Methods, where both types of architerure are mixed are also possible.
This work will focus on the second type, while also giving some theoretical insights to the decentralized approach.

\subsection{Sample Complexity}
One of the key questions of distributed learning is the number of samples required to obtain local models that are sufficiently good, i.e., when to stop learning and either start communication with the coordinator
or to terminate the algorithm and produce a final aggregate model. 
The problem to find the number of samples required is known to be hard \todo{cite} and as such no exacty solution to this problem exists.
However, an upper bound on the sample complexity is given by the Hoefding-Bound. 
We apply the Hoefding-Inequality on the pairwise difference between average sufficient statistics of local models.

The Hoefding-Inequality is given by
\begin{equation}
    P(\vect{\bar{X}} - \mathbb{E}[\vect{\bar{X}}] \geq t ) \leq \exp^{-2\abs{\mathcal{D}]t^2}},
\end{equation}

where for some constant $t$ the probability of the difference between the empirical mean of a random variable and its expectation is begin greater than $t$ is negatively exponential bounded by the amount of data seen.

It can be shown that for $t = \frac{\sqrt{(c+1) \log d}}{2\abs{\mathcal{D}}}$ the difference between two average sufficient statistics $\vect{\mu}^i = \frac{1}{\mathcal{D}_i} \sum_{x \in \mathcal{D}} \vect{\phi(x)}, \quad \vect{\phi(x)} \in \mathbb{R}^d$ of a probabilistic graphical model is bounded by
\begin{equation}
    \norm{\mu^{i} -  \mu^{j}}_\infty \leq 2 \sqrt{
        \frac{(c+1) \log d}
        {2\abs{\mathcal{D^{'}}}}
        } = \epsilon
\end{equation},
with probability of at least $\delta= (1- 2 \exp(-c \log d))$. Here $D^{'} = \min(\abs{\mathcal{D}^i}, \abs{\mathcal{D}^j})$.
The proof is provided by Piatkowski \cite{piatkowski2019distributed}. \todo{Maybe put this in appendix}
Addtionally, as the average sufficient statistics approach each other so do the model parameters to some degree as shown by \todo{CITE}.

As the model parameters approach each other, we can show by Popoviciu's Theorem
\begin{theorem}[Upper Bound on the Variance]
    Let $\vect{X}$ be a bounded random variable with $\inf(\vect{X}) = b$ and $\sup(\vect{X}) = a$, 
    then the variance $\sigma^2$ is bounded by 
    \begin{equation}
        \sigma^2 \leq \bigg(\frac{a-b}{2}\bigg)^{2}
    \end{equation}
\end{theorem}

\input{kapitel/proofs/popoviciu.tex}

It follows that
\begin{equation*}
    Var[\vect{X}] \leq f(\frac{a-b}{2}) \leq  \frac{1}{4} \cdot \mathbb{E}\bigg[\big((\vect{X} - b) - (\vect{X} - a)\big)^2\bigg]  =  \bigg(\frac{a-b}{2}\bigg)^2 
\end{equation*}\qed

Recall that $\norm{\vect{\mu}^{i} -  \vect{\mu}^{j}}_\infty \leq  \epsilon$, where $\epsilon$ provides the largest difference between two entries of the average sufficient statistics hence let $a - b = \mu^{i}_k - \mu^{j} = epsilon$.
This means that there exists no larger difference between the two vectors resulting in an upper bound for the variance of the average sufficient statistics with $a - b = \epsilon$ 
\begin{equation*}
    Var[\vect{\mu}^{i}_k -  \vect{\mu}^{j}_k] \leq \frac{\epsilon^2}{4} \quad \forall i,j,k
\end{equation*}.
Given two average sufficient statistics we can employ the Hoefding Bound to guarantee the distance between these two to be smaller than some $\epsilon$ with probability $\delta$

